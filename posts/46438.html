# hexo博客的SEO优化


## 1.给你的文章生成sitemap文件

 npm install hexo-generator-sitemap - -save #sitemap.xml适合提交给谷歌搜素引擎
 npm install hexo-generator-baidu-sitemap - -save #baidusitemap.xml适合提交百度搜索引擎
	

**然后在站点配置文件_config.yml中添加以下代码**

<!-- more -->

```Python
 sitemap:
       path: sitemap.xml
 baidusitemap:
       path: baidusitemap.xml
```		

注意缩进！
每次hexo g后都会在/public目录下生成sitemap.xml和baidusitemap.xml，这就是你的站点地图

## 2.文章URL的优化。
看本博客的URL 都是html后缀的静态url链接。且都是二级结构，用户点两次就能看到文章。要如何设置呢?
修改_config.yml 其中的一个字段 `permalink: article/:year:month:day:urlname.html` 可以参照此样式修改。
然后在  /你的hexo路径/scaffolds/post.md  增加字段urlname，如下 

---

> title: {{ title }}
> date: {{ date }}
> updated: {{ date }}
> tags:
> categories:
> urlname:  

---
urlname 最好用英文，这就是 xxxx.html  url会显示的名字。

## 3.robots.txt 文件的优化
在source目录下新增一个 robots.txt 文件，内容如下

---
> User-agent: * 
> Allow: /
> Allow: /archives/
> Allow: /article/
> 
> Disallow: /js/
> Disallow: /css/
> Disallow: /fonts/
> Disallow: /vendors/
> 
> Sitemap: https://www.mi20.top/sitemap.xml
>Sitemap: https://www.mi20.top/baidusitemap.xml

---

Allow 就是允许爬虫机器人访问的目录
Disallow 就是反义啦
